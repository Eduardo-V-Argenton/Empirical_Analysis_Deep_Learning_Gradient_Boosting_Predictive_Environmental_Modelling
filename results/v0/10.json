{
  "hidden_size": 256,
  "layers": 2,
  "learning_rate": 0.001,
  "batch_size": 64,
  "Loss": "HuberLoss",
  "Optimizer": "Adam",
  "bideretional": true,
  "dropout": 0.2,
  "MSE": 4.2897,
  "MAE": 1.6537,
  "R2": 0.9099,
  "weight_decay": 1e-4,
  "scheduler": {
    "algorithm": "ReduceLROnPlateau",
    "patience": 10,
    "factor": 0.5,
    "min_lr": 1e-6
  },
  "epochs": {
    "size": 200,
    "delta_losses": 5,
    "patience": {
      "epochs": 20,
      "method": "avg loss"
    },
    "losses": [
      0.0601, 0.0571, 0.0534, 0.0525, 0.0497, 0.0495, 0.0503, 0.0488, 0.0488,
      0.0468, 0.0463, 0.0466, 0.0463, 0.0461, 0.0461, 0.0448, 0.0448, 0.0447,
      0.0447, 0.0447, 0.0447, 0.0447, 0.0447, 0.0447, 0.0442, 0.0441, 0.0441,
      0.0441, 0.0441, 0.044, 0.0439, 0.0439, 0.0439, 0.0439, 0.0439, 0.0439,
      0.0439, 0.0439, 0.0438, 0.0438
    ]
  }
}
