{
  "hidden_size": 256,
  "layers": 2,
  "learning_rate": 0.001,
  "batch_size": 64,
  "Loss": "HuberLoss",
  "Optimizer": "Adam",
  "bideretional": false,
  "dropout": 0.2,
  "MSE": 4.2823,
  "MAE": 1.652,
  "R2": 0.91,
  "weight_decay": 1e-4,
  "scheduler": {
    "algorithm": "ReduceLROnPlateau",
    "patience": 10,
    "factor": 0.5,
    "min_lr": 1e-6
  },
  "epochs": {
    "size": 200,
    "delta_losses": 5,
    "patience": {
      "epochs": 20,
      "method": "avg loss"
    },
    "losses": [
      0.0607, 0.0546, 0.0522, 0.0522, 0.0503, 0.0479, 0.0485, 0.0481, 0.0479,
      0.0478, 0.0483, 0.0474, 0.0474, 0.0479, 0.0475, 0.0471, 0.0457, 0.0454,
      0.0456, 0.0456, 0.0456, 0.0453, 0.0453, 0.0444, 0.0444, 0.0444, 0.0444,
      0.0444, 0.0444, 0.044, 0.044, 0.044, 0.044, 0.044, 0.0439, 0.0438, 0.0438,
      0.0438, 0.0438, 0.0438
    ]
  }
}
