{
  "hidden_size": 256,
  "layers": 2,
  "learning_rate": 0.001,
  "batch_size": 64,
  "Loss": "LogCoshLoss",
  "Optimizer": "Adam",
  "bideretional": true,
  "dropout": 0.2,
  "MSE": 3.912,
  "MAE": 1.5809,
  "MAPE": 0.0848,
  "R2": 0.9178,
  "weight_decay": 1e-4,
  "scheduler": {
    "algorithm": "ReduceLROnPlateau",
    "patience": 10,
    "factor": 0.5,
    "min_lr": 1e-6
  },
  "epochs": {
    "size": 200,
    "delta_losses": 5,
    "patience": {
      "epochs": 20,
      "method": "avg loss"
    },
    "losses": [
      0.0645, 0.0406, 0.0403, 0.0406, 0.0403, 0.04, 0.0397, 0.0398, 0.0394,
      0.0394, 0.0393, 0.0395, 0.0393, 0.0394, 0.0393, 0.0393, 0.0391, 0.0392,
      0.0394, 0.0391, 0.0389, 0.039, 0.0388, 0.0387, 0.0387, 0.0387, 0.0387,
      0.0387, 0.0386, 0.0385, 0.0385, 0.0385, 0.0386, 0.0386, 0.0385, 0.0385,
      0.0385, 0.0384, 0.0384, 0.0384
    ]
  }
}
