{
  "hidden_size": 256,
  "layers": 2,
  "learning_rate": 0.001,
  "batch_size": 64,
  "Loss": "HuberLoss",
  "Optimizer": "Adam",
  "bideretional": true,
  "dropout": 0.2,
  "MSE": 4.3236,
  "MAE": 1.6601,
  "R2": 0.9091,
  "weight_decay": 1e-4,
  "scheduler": {
    "algorithm": "ReduceLROnPlateau",
    "patience": 10,
    "factor": 0.5,
    "min_lr": 1e-6
  },
  "epochs": {
    "size": 200,
    "delta_losses": 5,
    "patience": {
      "epochs": 20,
      "method": "avg loss"
    },
    "losses": [
      0.0556, 0.0544, 0.0555, 0.051, 0.0508, 0.0499, 0.0483, 0.0498, 0.0477,
      0.0487, 0.0477, 0.0476, 0.0483, 0.0473, 0.0467, 0.0461, 0.046, 0.0458,
      0.0459, 0.0459, 0.0456, 0.0459, 0.0461, 0.0449, 0.0448, 0.0448, 0.0448,
      0.0447, 0.0446, 0.0445, 0.0448, 0.0447, 0.0449, 0.0442, 0.0441, 0.0441,
      0.0441, 0.0441, 0.0439, 0.0439
    ]
  }
}
