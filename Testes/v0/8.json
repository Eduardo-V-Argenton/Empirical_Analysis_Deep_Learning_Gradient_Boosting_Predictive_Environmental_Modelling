{
  "hidden_size": 128,
  "layers": 2,
  "learning_rate": 0.001,
  "batch_size": 64,
  "Loss": "MSELoss",
  "Optimizer": "Adam",
  "bideretional": false,
  "dropout": 0.2,
  "MSE": 4.282,
  "MAE": 1.6524,
  "R2": 0.91,
  "weight_decay": 1e-4,
  "scheduler": {
    "patience": 5,
    "algorithm": "ReduceLROnPlateau"
  },
  "epochs": {
    "size": 200,
    "delta_losses": 5,
    "patience": {
      "epochs": 20,
      "method": "avg loss"
    },
    "losses": [
      0.1166, 0.1134, 0.1095, 0.0953, 0.0924, 0.0912, 0.0905, 0.0902, 0.0902,
      0.0902, 0.0898, 0.0893, 0.0891, 0.089, 0.0889, 0.0891, 0.0889, 0.0887,
      0.0887, 0.0887, 0.0885, 0.0885, 0.0885, 0.0884, 0.0884, 0.0884, 0.0883,
      0.0883, 0.0883, 0.0874, 0.0873, 0.0873, 0.0873, 0.0873, 0.0873, 0.0873,
      0.0872, 0.0872, 0.0872, 0.0872
    ]
  }
}
