{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:27:16.231443Z",
     "start_time": "2025-06-05T14:27:16.229041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import BlockRNNModel\n",
    "from darts.metrics import mse, rmse, r2_score, mae, smape\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from plotnine import (\n",
    "    ggplot, aes, geom_line, facet_wrap, labs, theme_bw, theme,\n",
    "    element_text, element_blank, facet_grid\n",
    ")\n",
    "import json\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n"
   ],
   "id": "c8e322316e78e4af",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:27:16.298773Z",
     "start_time": "2025-06-05T14:27:16.287380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_columns = [\n",
    "    'Temperature','Precipitation_accumulated','Humidity', 'Wind_Speed_kmh',\n",
    "    'Soil_Moisture', 'Soil_Temperature', 'Wind_Dir_Sin', 'Wind_Dir_Cos'\n",
    "]\n",
    "\n",
    "DATA_FILE_PATH = \"data/ground_station_clean.csv\"\n",
    "df = pd.read_csv(DATA_FILE_PATH)"
   ],
   "id": "d86fa6ae8d43e380",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:27:16.374467Z",
     "start_time": "2025-06-05T14:27:16.372552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoders = {\n",
    "    \"cyclic\": {\n",
    "        \"past\": [\"month\", \"dayofyear\", \"day\", \"hour\", \"minute\"],\n",
    "        \"future\": [\"month\", \"dayofyear\", \"day\", \"hour\", \"minute\"]\n",
    "    },\n",
    "    \"transformer\": Scaler(),\n",
    "    \"datetime_attribute\": {\n",
    "        \"past\": [\"year\"],\n",
    "        \"future\": [\"year\"]\n",
    "    }\n",
    "}"
   ],
   "id": "765bb8940fb41d7c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:42.688937Z",
     "start_time": "2025-06-05T14:27:16.462912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_mse = float('inf')\n",
    "best_fold = -1\n",
    "best_train_scaled = None\n",
    "best_val_scaled = None\n",
    "best_scaler = None\n",
    "best_metrics = None\n",
    "best_forecasts = None\n",
    "# Definir parâmetros do modelo\n",
    "\n",
    "# Listas para armazenar dados de todos os folds\n",
    "all_forecasts = []\n",
    "all_val_scaled = []\n",
    "all_scalers = []\n",
    "all_metrics_dfs = []\n",
    "all_r2_scores = []\n",
    "all_mse_scores = []\n",
    "all_train_scaled = []\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "fold_metrics = []\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(df)):\n",
    "\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.001, patience=10, verbose=True)\n",
    "    pl_trainer_kwargs = {\n",
    "        \"accelerator\": \"auto\",\n",
    "        \"callbacks\": [early_stopper],\n",
    "    }\n",
    "    train_df_fold, val_df_fold = df.iloc[train_idx], df.iloc[val_idx]\n",
    "    train_fold = TimeSeries.from_dataframe(train_df_fold, time_col=\"Timestamp\", value_cols=target_columns, freq='1h')\n",
    "    val_fold = TimeSeries.from_dataframe(val_df_fold, time_col=\"Timestamp\", value_cols=target_columns, freq='1h')\n",
    "\n",
    "    print(f\"\\n{'='*50}\\nFold {fold+1}\\n{'='*50}\")\n",
    "    print(\"\\nTreinando o modelo...\")\n",
    "    print(f\"Train set: {train_fold.shape[0]} samples\")\n",
    "    print(f\"Validation set: {val_fold.shape[0]} samples\")\n",
    "\n",
    "    scaler = Scaler()\n",
    "    # Ajustar o scaler apenas nos dados de treino para evitar data leakage\n",
    "    scaler = scaler.fit(train_fold)\n",
    "    # Transformar todas as séries\n",
    "    train_scaled = scaler.transform(train_fold)\n",
    "    val_scaled = scaler.transform(val_fold)\n",
    "\n",
    "\n",
    "    model = BlockRNNModel(\n",
    "        model=\"LSTM\",\n",
    "        model_name=f\"model_{fold+1}\",\n",
    "        input_chunk_length=31,\n",
    "        output_chunk_length=72,\n",
    "        hidden_dim=64,\n",
    "        n_rnn_layers=1,\n",
    "        n_epochs=100,\n",
    "        batch_size=64,\n",
    "        dropout=0.1,\n",
    "        add_encoders=encoders,\n",
    "        pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        optimizer_cls=torch.optim.Adam,\n",
    "        lr_scheduler_cls=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        lr_scheduler_kwargs={\"mode\":\"min\", \"factor\":0.5, \"patience\":4, \"min_lr\":1e-6},\n",
    "        save_checkpoints=True,\n",
    "        show_warnings=True,\n",
    "        force_reset=True,\n",
    "        random_state=42,\n",
    "        optimizer_kwargs={\"lr\": 0.0025733926460366017, \"weight_decay\": 1.4247838819125532e-05},\n",
    "    )\n",
    "    model.fit(\n",
    "        series=train_scaled,\n",
    "        val_series=val_scaled,\n",
    "        dataloader_kwargs={\"num_workers\": 11},\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    model.load_from_checkpoint(f\"/home/eduardo/Documentos/Water-Cycle-Neural-Network/darts_logs/model_{fold+1}/\", best=True)\n",
    "\n",
    "    forecasts = model.historical_forecasts(\n",
    "        val_scaled,\n",
    "        forecast_horizon=72,\n",
    "        stride=1,\n",
    "        retrain=False,\n",
    "        verbose=False,\n",
    "        last_points_only=True,\n",
    "    ) \n",
    "\n",
    "    forecasts_t = scaler.inverse_transform(forecasts)\n",
    "    s = scaler.inverse_transform(val_scaled)\n",
    "    metrics = {}\n",
    "    print(\"Iniciando a verificação das séries temporais para constância...\")\n",
    "    try:\n",
    "        for target in target_columns:\n",
    "            metrics[target] = {\n",
    "                'MSE': mse(s[target], forecasts_t[target]),\n",
    "                'RMSE': rmse(s[target], forecasts_t[target]),\n",
    "                'MAE': mae(s[target], forecasts_t[target]),\n",
    "                'R2': r2_score(s[target], forecasts_t[target]),\n",
    "                'SMAPE': smape(s[target], forecasts_t[target]),\n",
    "            }\n",
    "        metrics_df = pd.DataFrame(metrics).T\n",
    "        print(\"\\nMétricas de performance:\")\n",
    "        print(metrics_df)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    r2_geral = r2_score(s, forecasts_t)\n",
    "    mse_geral = mse(s, forecasts_t)\n",
    "    print(f\"O R2 desse fold foi {r2_geral}\")\n",
    "    print(f\"O MSE desse fold foi {mse_geral}\")\n",
    "\n",
    "    # Armazenar dados deste fold\n",
    "    all_forecasts.append(forecasts)\n",
    "    all_val_scaled.append(val_scaled)\n",
    "    all_scalers.append(scaler)\n",
    "    all_metrics_dfs.append(metrics_df)\n",
    "    all_r2_scores.append(r2_geral)\n",
    "    all_mse_scores.append(mse_geral)\n",
    "    all_train_scaled.append(train_scaled)\n",
    "\n",
    "    # Ainda mantemos o melhor fold para referência (agora baseado no MSE)\n",
    "    if best_mse > mse_geral:\n",
    "        best_mse = mse_geral\n",
    "        best_fold = fold + 1\n",
    "        best_train_scaled = train_scaled\n",
    "        best_scaler = scaler\n",
    "        best_metrics = metrics_df\n",
    "        best_forecasts = forecasts\n",
    "        best_val_scaled = val_scaled\n",
    "\n",
    "print(f\"O melhor fold (baseado no menor MSE) foi {best_fold}\")\n",
    "\n",
    "# Calcular a média dos R2 e MSE de todos os folds\n",
    "avg_r2 = sum(all_r2_scores) / len(all_r2_scores)\n",
    "avg_mse = sum(all_mse_scores) / len(all_mse_scores)\n",
    "print(f\"A média dos R2 de todos os folds foi {avg_r2:.4f}\")\n",
    "print(f\"A média dos MSE de todos os folds foi {avg_mse:.4f}\")\n",
    "\n",
    "# Calcular a média das métricas para cada coluna alvo\n",
    "avg_metrics = {}\n",
    "for target in target_columns:\n",
    "    avg_metrics[target] = {\n",
    "        'MSE': sum(df[target]['MSE'] for df in all_metrics_dfs) / len(all_metrics_dfs),\n",
    "        'RMSE': sum(df[target]['RMSE'] for df in all_metrics_dfs) / len(all_metrics_dfs),\n",
    "        'MAE': sum(df[target]['MAE'] for df in all_metrics_dfs) / len(all_metrics_dfs),\n",
    "        'R2': sum(df[target]['R2'] for df in all_metrics_dfs) / len(all_metrics_dfs),\n",
    "        'SMAPE': sum(df[target]['SMAPE'] for df in all_metrics_dfs) / len(all_metrics_dfs),\n",
    "    }\n",
    "avg_metrics_df = pd.DataFrame(avg_metrics).T\n",
    "print(\"\\nMétricas médias de performance de todos os folds:\")\n",
    "print(avg_metrics_df)\n",
    "\n",
    "# Salvar métricas médias\n",
    "with open('avg_metrics.json', 'w') as f:\n",
    "    json.dump(avg_metrics_df.to_dict(), f, indent=4)\n",
    "\n",
    "print(\"\\nUsando a média dos folds para análise...\")\n"
   ],
   "id": "5de5987b68fe3c25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Fold 1\n",
      "==================================================\n",
      "\n",
      "Treinando o modelo...\n",
      "Train set: 1389 samples\n",
      "Validation set: 1384 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Specified future encoders in `add_encoders` at model creation but model does not accept future covariates. future encoders will be ignored.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Metric val_loss improved. New best score: 1025.559\n",
      "Metric val_loss improved by 1.158 >= min_delta = 0.001. New best score: 1024.401\n",
      "Metric val_loss improved by 1.058 >= min_delta = 0.001. New best score: 1023.343\n",
      "Metric val_loss improved by 2.760 >= min_delta = 0.001. New best score: 1020.583\n",
      "Metric val_loss improved by 0.818 >= min_delta = 0.001. New best score: 1019.765\n",
      "Metric val_loss improved by 0.137 >= min_delta = 0.001. New best score: 1019.627\n",
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 1019.627. Signaling Trainer to stop.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: PossibleUserWarning: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "Specified future encoders in `add_encoders` at model creation but model does not accept future covariates. future encoders will be ignored.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a verificação das séries temporais para constância...\n",
      "\n",
      "Métricas de performance:\n",
      "                                     MSE        RMSE         MAE        R2  \\\n",
      "Temperature                    49.629596    7.044828    5.539431 -0.057545   \n",
      "Precipitation_accumulated   62125.927331  249.250732  138.701528 -0.459705   \n",
      "Humidity                      894.217940   29.903477   24.980595 -1.888910   \n",
      "Wind_Speed_kmh                  0.443223    0.665750    0.515364  0.091570   \n",
      "Soil_Moisture              737167.346722  858.584502  719.765073  0.406483   \n",
      "Soil_Temperature              212.146866   14.565262   10.488086 -2.690454   \n",
      "Wind_Dir_Sin                    0.636903    0.798062    0.592900 -0.759108   \n",
      "Wind_Dir_Cos                    0.882231    0.939271    0.818313 -0.542116   \n",
      "\n",
      "                                SMAPE  \n",
      "Temperature                 33.540783  \n",
      "Precipitation_accumulated   87.928575  \n",
      "Humidity                    38.734433  \n",
      "Wind_Speed_kmh              76.742910  \n",
      "Soil_Moisture                9.103556  \n",
      "Soil_Temperature            48.472086  \n",
      "Wind_Dir_Sin               119.849425  \n",
      "Wind_Dir_Cos               147.449826  \n",
      "O R2 desse fold foi -0.7374732022201943\n",
      "O MSE desse fold foi 100056.4038515481\n",
      "\n",
      "==================================================\n",
      "Fold 2\n",
      "==================================================\n",
      "\n",
      "Treinando o modelo...\n",
      "Train set: 2773 samples\n",
      "Validation set: 1384 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.036\n",
      "Metric val_loss improved by 0.018 >= min_delta = 0.001. New best score: 0.017\n",
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.017. Signaling Trainer to stop.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: PossibleUserWarning: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/darts/metrics/metrics.py:2930: RuntimeWarning: divide by zero encountered in divide\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/darts/metrics/metrics.py:2930: RuntimeWarning: divide by zero encountered in divide\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/darts/metrics/metrics.py:2930: RuntimeWarning: divide by zero encountered in divide\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/darts/metrics/metrics.py:2930: RuntimeWarning: divide by zero encountered in divide\n",
      "Specified future encoders in `add_encoders` at model creation but model does not accept future covariates. future encoders will be ignored.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a verificação das séries temporais para constância...\n",
      "\n",
      "Métricas de performance:\n",
      "                                    MSE        RMSE         MAE            R2  \\\n",
      "Temperature                   25.177053    5.017674    4.221444 -2.367920e+00   \n",
      "Precipitation_accumulated    603.860123   24.573566   19.109857 -3.557340e+05   \n",
      "Humidity                      74.740747    8.645273    6.985075 -2.574801e+00   \n",
      "Wind_Speed_kmh                 0.084680    0.290998    0.249749          -inf   \n",
      "Soil_Moisture              54433.201707  233.309241  189.434313 -9.897585e+00   \n",
      "Soil_Temperature              35.098165    5.924370    4.856888 -3.300970e+00   \n",
      "Wind_Dir_Sin                   0.124274    0.352525    0.293218          -inf   \n",
      "Wind_Dir_Cos                   0.334345    0.578225    0.428998          -inf   \n",
      "\n",
      "                                SMAPE  \n",
      "Temperature                 31.226006  \n",
      "Precipitation_accumulated    4.308135  \n",
      "Humidity                     8.296686  \n",
      "Wind_Speed_kmh             200.000000  \n",
      "Soil_Moisture                2.924321  \n",
      "Soil_Temperature            40.836000  \n",
      "Wind_Dir_Sin               200.000000  \n",
      "Wind_Dir_Cos                71.964156  \n",
      "O R2 desse fold foi -inf\n",
      "O MSE desse fold foi 6896.577636740453\n",
      "\n",
      "==================================================\n",
      "Fold 3\n",
      "==================================================\n",
      "\n",
      "Treinando o modelo...\n",
      "Train set: 4157 samples\n",
      "Validation set: 1384 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.008\n",
      "Metric val_loss improved by 0.002 >= min_delta = 0.001. New best score: 0.006\n",
      "Metric val_loss improved by 0.001 >= min_delta = 0.001. New best score: 0.005\n",
      "Metric val_loss improved by 0.001 >= min_delta = 0.001. New best score: 0.004\n",
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.004. Signaling Trainer to stop.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: PossibleUserWarning: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/darts/metrics/metrics.py:2930: RuntimeWarning: divide by zero encountered in divide\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/darts/metrics/metrics.py:2930: RuntimeWarning: divide by zero encountered in divide\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/darts/metrics/metrics.py:2930: RuntimeWarning: divide by zero encountered in divide\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/darts/metrics/metrics.py:2930: RuntimeWarning: divide by zero encountered in divide\n",
      "Specified future encoders in `add_encoders` at model creation but model does not accept future covariates. future encoders will be ignored.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a verificação das séries temporais para constância...\n",
      "\n",
      "Métricas de performance:\n",
      "                                     MSE        RMSE         MAE           R2  \\\n",
      "Temperature                     2.079524    1.442055    1.236499    -2.995265   \n",
      "Precipitation_accumulated     152.538659   12.350654   10.897907 -3835.282473   \n",
      "Humidity                        9.562892    3.092393    2.466296     0.017962   \n",
      "Wind_Speed_kmh                  0.004913    0.070094    0.053654         -inf   \n",
      "Soil_Moisture              295941.493572  544.005049  477.136663    -8.351070   \n",
      "Soil_Temperature                1.580959    1.257362    1.089337    -8.242453   \n",
      "Wind_Dir_Sin                    0.012022    0.109644    0.085142         -inf   \n",
      "Wind_Dir_Cos                    0.014127    0.118858    0.111069         -inf   \n",
      "\n",
      "                                SMAPE  \n",
      "Temperature                 12.641905  \n",
      "Precipitation_accumulated    2.382636  \n",
      "Humidity                     2.717623  \n",
      "Wind_Speed_kmh             200.000000  \n",
      "Soil_Moisture                7.768591  \n",
      "Soil_Temperature            10.923077  \n",
      "Wind_Dir_Sin               200.000000  \n",
      "Wind_Dir_Cos                11.866831  \n",
      "O R2 desse fold foi -inf\n",
      "O MSE desse fold foi 37013.410833457565\n",
      "\n",
      "==================================================\n",
      "Fold 4\n",
      "==================================================\n",
      "\n",
      "Treinando o modelo...\n",
      "Train set: 5541 samples\n",
      "Validation set: 1384 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.043\n",
      "Metric val_loss improved by 0.004 >= min_delta = 0.001. New best score: 0.039\n",
      "Metric val_loss improved by 0.002 >= min_delta = 0.001. New best score: 0.037\n",
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.037. Signaling Trainer to stop.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: PossibleUserWarning: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "Specified future encoders in `add_encoders` at model creation but model does not accept future covariates. future encoders will be ignored.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a verificação das séries temporais para constância...\n",
      "\n",
      "Métricas de performance:\n",
      "                                    MSE         RMSE         MAE          R2  \\\n",
      "Temperature                1.538479e+01     3.922346    3.287874   -1.878325   \n",
      "Precipitation_accumulated  1.705480e+02    13.059404   10.032015 -147.912517   \n",
      "Humidity                   1.822688e+02    13.500697   11.990459   -1.104658   \n",
      "Wind_Speed_kmh             9.072261e-01     0.952484    0.499021    0.024801   \n",
      "Soil_Moisture              1.803547e+06  1342.961848  848.295920   -0.289200   \n",
      "Soil_Temperature           2.214491e+01     4.705838    4.006197   -2.794266   \n",
      "Wind_Dir_Sin               3.092168e-01     0.556073    0.380285   -0.105694   \n",
      "Wind_Dir_Cos               6.856294e-01     0.828027    0.509599   -0.439639   \n",
      "\n",
      "                                SMAPE  \n",
      "Temperature                 52.429526  \n",
      "Precipitation_accumulated    2.216454  \n",
      "Humidity                    13.800382  \n",
      "Wind_Speed_kmh             156.281055  \n",
      "Soil_Moisture               12.266740  \n",
      "Soil_Temperature            62.456393  \n",
      "Wind_Dir_Sin               181.018830  \n",
      "Wind_Dir_Cos                73.510894  \n",
      "O R2 desse fold foi -19.312437296093158\n",
      "O MSE desse fold foi 225492.34688138354\n",
      "\n",
      "==================================================\n",
      "Fold 5\n",
      "==================================================\n",
      "\n",
      "Treinando o modelo...\n",
      "Train set: 6925 samples\n",
      "Validation set: 1384 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.061\n",
      "Metric val_loss improved by 0.019 >= min_delta = 0.001. New best score: 0.042\n",
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.042. Signaling Trainer to stop.\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/eduardo/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: PossibleUserWarning: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a verificação das séries temporais para constância...\n",
      "\n",
      "Métricas de performance:\n",
      "                                     MSE        RMSE         MAE  \\\n",
      "Temperature                    20.454685    4.522686    3.469452   \n",
      "Precipitation_accumulated   67543.047281  259.890452  206.338596   \n",
      "Humidity                      132.425504   11.507628    9.175701   \n",
      "Wind_Speed_kmh                  1.739347    1.318843    1.091039   \n",
      "Soil_Moisture              572751.451629  756.803443  633.147167   \n",
      "Soil_Temperature               14.734482    3.838552    3.196865   \n",
      "Wind_Dir_Sin                    0.713493    0.844685    0.760380   \n",
      "Wind_Dir_Cos                    0.603202    0.776661    0.623707   \n",
      "\n",
      "                                     R2       SMAPE  \n",
      "Temperature                    0.247009   41.195942  \n",
      "Precipitation_accumulated -50712.726114   69.077649  \n",
      "Humidity                       0.159767   10.847503  \n",
      "Wind_Speed_kmh                -0.358534   76.091427  \n",
      "Soil_Moisture                -93.066137    6.977959  \n",
      "Soil_Temperature              -0.188241   54.723727  \n",
      "Wind_Dir_Sin                  -0.290499  162.669285  \n",
      "Wind_Dir_Cos                  -0.716353  121.016689  \n",
      "O R2 desse fold foi -6350.867387838232\n",
      "O MSE desse fold foi 80058.1462028735\n",
      "O melhor fold (baseado no menor MSE) foi 2\n",
      "A média dos R2 de todos os folds foi -inf\n",
      "A média dos MSE de todos os folds foi 89903.3771\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Temperature'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3804\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3805\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3806\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'Temperature'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 140\u001B[39m\n\u001B[32m    137\u001B[39m avg_metrics = {}\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m target \u001B[38;5;129;01min\u001B[39;00m target_columns:\n\u001B[32m    139\u001B[39m     avg_metrics[target] = {\n\u001B[32m--> \u001B[39m\u001B[32m140\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mMSE\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mMSE\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mall_metrics_dfs\u001B[49m\u001B[43m)\u001B[49m / \u001B[38;5;28mlen\u001B[39m(all_metrics_dfs),\n\u001B[32m    141\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mRMSE\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28msum\u001B[39m(df[target][\u001B[33m'\u001B[39m\u001B[33mRMSE\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m all_metrics_dfs) / \u001B[38;5;28mlen\u001B[39m(all_metrics_dfs),\n\u001B[32m    142\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mMAE\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28msum\u001B[39m(df[target][\u001B[33m'\u001B[39m\u001B[33mMAE\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m all_metrics_dfs) / \u001B[38;5;28mlen\u001B[39m(all_metrics_dfs),\n\u001B[32m    143\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mR2\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28msum\u001B[39m(df[target][\u001B[33m'\u001B[39m\u001B[33mR2\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m all_metrics_dfs) / \u001B[38;5;28mlen\u001B[39m(all_metrics_dfs),\n\u001B[32m    144\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mSMAPE\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28msum\u001B[39m(df[target][\u001B[33m'\u001B[39m\u001B[33mSMAPE\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m all_metrics_dfs) / \u001B[38;5;28mlen\u001B[39m(all_metrics_dfs),\n\u001B[32m    145\u001B[39m     }\n\u001B[32m    146\u001B[39m avg_metrics_df = pd.DataFrame(avg_metrics).T\n\u001B[32m    147\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mMétricas médias de performance de todos os folds:\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 140\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    137\u001B[39m avg_metrics = {}\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m target \u001B[38;5;129;01min\u001B[39;00m target_columns:\n\u001B[32m    139\u001B[39m     avg_metrics[target] = {\n\u001B[32m--> \u001B[39m\u001B[32m140\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mMSE\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28msum\u001B[39m(\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m]\u001B[49m[\u001B[33m'\u001B[39m\u001B[33mMSE\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m all_metrics_dfs) / \u001B[38;5;28mlen\u001B[39m(all_metrics_dfs),\n\u001B[32m    141\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mRMSE\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28msum\u001B[39m(df[target][\u001B[33m'\u001B[39m\u001B[33mRMSE\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m all_metrics_dfs) / \u001B[38;5;28mlen\u001B[39m(all_metrics_dfs),\n\u001B[32m    142\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mMAE\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28msum\u001B[39m(df[target][\u001B[33m'\u001B[39m\u001B[33mMAE\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m all_metrics_dfs) / \u001B[38;5;28mlen\u001B[39m(all_metrics_dfs),\n\u001B[32m    143\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mR2\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28msum\u001B[39m(df[target][\u001B[33m'\u001B[39m\u001B[33mR2\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m all_metrics_dfs) / \u001B[38;5;28mlen\u001B[39m(all_metrics_dfs),\n\u001B[32m    144\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mSMAPE\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28msum\u001B[39m(df[target][\u001B[33m'\u001B[39m\u001B[33mSMAPE\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m all_metrics_dfs) / \u001B[38;5;28mlen\u001B[39m(all_metrics_dfs),\n\u001B[32m    145\u001B[39m     }\n\u001B[32m    146\u001B[39m avg_metrics_df = pd.DataFrame(avg_metrics).T\n\u001B[32m    147\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mMétricas médias de performance de todos os folds:\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4100\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4101\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4102\u001B[39m indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4103\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4104\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documentos/Water-Cycle-Neural-Network/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3807\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3808\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3809\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3810\u001B[39m     ):\n\u001B[32m   3811\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3814\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3815\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3816\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3817\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'Temperature'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ainda carregamos o modelo do melhor fold para previsões\n",
    "model.load_from_checkpoint(f\"/home/eduardo/Documentos/Water-Cycle-Neural-Network/darts_logs/model_{best_fold}/\", best=True)"
   ],
   "id": "da751795d13381b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preparar dados para visualização usando a média dos folds\n",
    "# Primeiro, vamos transformar os dados de cada fold\n",
    "all_s_dfs = []\n",
    "all_forecasts_dfs = []\n",
    "\n",
    "for i, (val_scaled, forecasts, scaler) in enumerate(zip(all_val_scaled, all_forecasts, all_scalers)):\n",
    "    # Transformar dados de validação\n",
    "    s_fold = scaler.inverse_transform(val_scaled)\n",
    "    s_fold_df = s_fold.to_dataframe()\n",
    "    s_fold_df = s_fold_df.reset_index()\n",
    "    s_fold_df['fold'] = i + 1\n",
    "    all_s_dfs.append(s_fold_df)\n",
    "\n",
    "    # Transformar previsões\n",
    "    forecasts_fold = scaler.inverse_transform(forecasts)\n",
    "    forecasts_fold_df = forecasts_fold.to_dataframe()\n",
    "    forecasts_fold_df = forecasts_fold_df.reset_index()\n",
    "    forecasts_fold_df['fold'] = i + 1\n",
    "    all_forecasts_dfs.append(forecasts_fold_df)\n",
    "\n",
    "# Combinar todos os dataframes\n",
    "s_df = pd.concat(all_s_dfs)\n",
    "forecasts_t_df = pd.concat(all_forecasts_dfs)\n",
    "\n",
    "# Renomear colunas para consistência\n",
    "s_df = s_df.rename(columns={\"time\": \"Timestamp\"})\n",
    "forecasts_t_df = forecasts_t_df.rename(columns={\"time\": \"Timestamp\"})\n",
    "\n",
    "# Para referência, também mantemos os dados do melhor fold\n",
    "s_best = best_scaler.inverse_transform(best_val_scaled)\n",
    "forecasts_t_best = best_scaler.inverse_transform(best_forecasts)\n",
    "print(forecasts_t_df.columns)"
   ],
   "id": "bb2ed2172d2a585",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_columns = ['Timestamp', 'fold'] + target_columns\n",
    "s_melted = s_df[plot_columns].melt(\n",
    "    id_vars=['Timestamp', 'fold'],\n",
    "    var_name='target_column',\n",
    "    value_name='value'\n",
    ")\n",
    "s_melted['type'] = 'Actual'\n",
    "\n",
    "forecasts_t_melted = forecasts_t_df[plot_columns].melt(\n",
    "    id_vars=['Timestamp', 'fold'],\n",
    "    var_name='target_column',\n",
    "    value_name='value'\n",
    ")\n",
    "forecasts_t_melted['type'] = 'Predicted'\n",
    "\n",
    "df_combined = pd.concat([s_melted, forecasts_t_melted])\n",
    "\n",
    "df_combined = df_combined.rename(columns={'Timestamp': 'Date'})\n",
    "\n",
    "# Também criar uma versão agregada (média) para cada target e timestamp\n",
    "df_avg = df_combined.groupby(['Date', 'target_column', 'type']).agg({'value': 'mean'}).reset_index()\n",
    "df_avg['fold'] = 'Média'\n",
    "\n",
    "# Combinar os dados médios com os dados originais\n",
    "df_all = pd.concat([df_combined, df_avg])\n",
    "\n",
    "# Plot 1: Média de todos os folds\n",
    "plot_avg = (\n",
    "    ggplot(df_avg, aes(x='Date', y='value', color='type'))\n",
    "    + geom_line(size=1)\n",
    "    + facet_wrap('~ target_column', scales='free_y')\n",
    "    + labs(\n",
    "        title='Predicted vs actual (média de todos os folds)',\n",
    "        x='Data',\n",
    "        y='Value',\n",
    "        color='Data type'\n",
    "    )\n",
    "    + theme_bw()\n",
    "    + theme(\n",
    "        axis_text_x=element_text(rotation=45, hjust=1),\n",
    "        legend_position='bottom',\n",
    "        legend_title=element_blank(),\n",
    "    )\n",
    ")\n",
    "plot_avg.show()\n",
    "plot_avg.save('predict_actual_avg.png', width=12, height=10, dpi=300)\n",
    "\n",
    "# Plot 2: Todos os folds separados por target\n",
    "plot_all_folds = (\n",
    "    ggplot(df_combined, aes(x='Date', y='value', color='type'))\n",
    "    + geom_line(alpha=0.7)\n",
    "    + facet_grid('fold ~ target_column', scales='free_y')\n",
    "    + labs(\n",
    "        title='Predicted vs actual (todos os folds)',\n",
    "        x='Data',\n",
    "        y='Value',\n",
    "        color='Data type'\n",
    "    )\n",
    "    + theme_bw()\n",
    "    + theme(\n",
    "        axis_text_x=element_text(rotation=45, hjust=1),\n",
    "        legend_position='bottom',\n",
    "        legend_title=element_blank(),\n",
    "        strip_text_y=element_text(angle=0)\n",
    "    )\n",
    ")\n",
    "plot_all_folds.show()\n",
    "plot_all_folds.save('predict_actual_all_folds.png', width=15, height=20, dpi=300)\n",
    "\n",
    "# Plot 3: Comparação da média com o melhor fold\n",
    "# Primeiro, preparar os dados do melhor fold\n",
    "best_fold_data = df_combined[df_combined['fold'] == best_fold]\n",
    "best_fold_data['fold'] = 'Melhor Fold'\n",
    "comparison_data = pd.concat([df_avg, best_fold_data])\n",
    "\n",
    "plot_comparison = (\n",
    "    ggplot(comparison_data, aes(x='Date', y='value', color='type', linetype='fold'))\n",
    "    + geom_line()\n",
    "    + facet_wrap('~ target_column', scales='free_y')\n",
    "    + labs(\n",
    "        title='Comparação: Média de todos os folds vs Melhor fold',\n",
    "        x='Data',\n",
    "        y='Value',\n",
    "        color='Data type'\n",
    "    )\n",
    "    + theme_bw()\n",
    "    + theme(\n",
    "        axis_text_x=element_text(rotation=45, hjust=1),\n",
    "        legend_position='bottom',\n",
    "        legend_title=element_blank(),\n",
    "    )\n",
    ")\n",
    "plot_comparison.show()\n",
    "plot_comparison.save('predict_actual_comparison.png', width=12, height=10, dpi=300)"
   ],
   "id": "e43f45d95655fd47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Salvar métricas do melhor fold\n",
    "with open('best_metrics.json', 'w') as f:\n",
    "    json.dump(best_metrics.to_dict(), f, indent=4)\n",
    "\n",
    "# Salvar métricas médias\n",
    "with open('avg_metrics.json', 'w') as f:\n",
    "    json.dump(avg_metrics_df.to_dict(), f, indent=4)\n",
    "\n",
    "# Salvar todas as métricas em um único arquivo\n",
    "all_metrics = {\n",
    "    'average': avg_metrics_df.to_dict(),\n",
    "    'best_fold': best_metrics.to_dict(),\n",
    "    'all_folds': {f'fold_{i+1}': df.to_dict() for i, df in enumerate(all_metrics_dfs)}\n",
    "}\n",
    "with open('all_metrics.json', 'w') as f:\n",
    "    json.dump(all_metrics, f, indent=4)\n",
    "\n",
    "print(\"\\nAnálise completa! Os resultados foram salvos usando a média de todos os folds.\")\n"
   ],
   "id": "c47382185882c786",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (TORCH)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
