{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models.forecasting.lgbm import LightGBMModel\n",
    "from darts.metrics import mse, rmse, r2_score, mae, smape\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import torch\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
    "import optuna\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "torch.set_float32_matmul_precision('medium')"
   ],
   "id": "6ce07af8617d198a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target_columns = [\n",
    "    'Temperature','Precipitation_accumulated','Humidity', 'Wind_Speed_kmh',\n",
    "    'Soil_Moisture', 'Soil_Temperature', 'Wind_Dir_Sin', 'Wind_Dir_Cos'\n",
    "]\n",
    "\n",
    "DATA_FILE_PATH = \"../data/ground_station_clean.csv\"\n",
    "df = pd.read_csv(DATA_FILE_PATH)"
   ],
   "id": "aa0a312a859d7977",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "encoders = {\n",
    "    \"cyclic\": {\n",
    "        \"past\": [\"month\", \"dayofyear\", \"day\", \"hour\", \"minute\"],\n",
    "        \"future\": [\"month\", \"dayofyear\", \"day\", \"hour\", \"minute\"]\n",
    "    },\n",
    "    \"transformer\": Scaler(),\n",
    "    \"datetime_attribute\": {\n",
    "        \"past\": [\"year\"],\n",
    "        \"future\": [\"year\"]\n",
    "    }\n",
    "}\n"
   ],
   "id": "f10cf40cbefd1b5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PatchedPruningCallback(PyTorchLightningPruningCallback, Callback):\n",
    "    pass\n",
    "\n",
    "# Create directory to save iteration results\n",
    "results_output_dir = \"optuna_iteration_metrics\"\n",
    "os.makedirs(results_output_dir, exist_ok=True)"
   ],
   "id": "7db1ea2bc89fa74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    num_target_lags = trial.suggest_int('num_target_lags', 5, 24)\n",
    "    target_lags_list = [-i for i in range(1, num_target_lags + 1)]\n",
    "    params = {\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 800, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150, step=5),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50, step=5),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0, step=0.05),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0, step=0.05),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 1.0, log=True),\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "    n = int(len(df) * 0.8)\n",
    "    train_df_fold, val_df_fold = df.iloc[:n], df.iloc[n:]\n",
    "    train_fold = TimeSeries.from_dataframe(train_df_fold, time_col=\"Timestamp\", value_cols=target_columns, freq='1h')\n",
    "    val_fold = TimeSeries.from_dataframe(val_df_fold, time_col=\"Timestamp\", value_cols=target_columns, freq='1h')\n",
    "\n",
    "    print(f\"\\nStarting Trial {trial.number}\")\n",
    "    print(f\"Hyperparameters: {trial.params}\")\n",
    "    print(\"\\nTraining the model...\")\n",
    "    print(f\"Train set: {len(train_fold)} samples\")\n",
    "    print(f\"Validation set: {len(val_fold)} samples\")\n",
    "\n",
    "    scaler = Scaler()\n",
    "    scaler = scaler.fit(train_fold)\n",
    "    train_scaled = scaler.transform(train_fold)\n",
    "    val_scaled = scaler.transform(val_fold)\n",
    "\n",
    "    _work_dir = \"/home/eduardo/Documentos/Water-Cycle-Neural-Network/darts_logs/\"\n",
    "    _model_name = \"model_optuna_temp\"\n",
    "    os.makedirs(_work_dir, exist_ok=True)\n",
    "\n",
    "    model = LightGBMModel(\n",
    "        lags=target_lags_list,\n",
    "        add_encoders=encoders,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        series=train_scaled,\n",
    "        val_series=val_scaled,\n",
    "    )\n",
    "\n",
    "    forecasts = model.historical_forecasts(\n",
    "        val_scaled,\n",
    "        forecast_horizon=1,\n",
    "        stride=1,\n",
    "        retrain=False,\n",
    "    )\n",
    "\n",
    "    forecasts_t = scaler.inverse_transform(forecasts)\n",
    "    s = scaler.inverse_transform(val_scaled)\n",
    "    metrics = {}\n",
    "    print(\"Starting time series verification for consistency...\")\n",
    "    try:\n",
    "        for target in target_columns:\n",
    "            metrics[target] = {\n",
    "                'MSE': mse(s[target], forecasts_t[target]),\n",
    "                'RMSE': rmse(s[target], forecasts_t[target]),\n",
    "                'MAE': mae(s[target], forecasts_t[target]),\n",
    "                'R2': r2_score(s[target], forecasts_t[target]),\n",
    "                'SMAPE': smape(s[target], forecasts_t[target]),\n",
    "            }\n",
    "        metrics_df = pd.DataFrame(metrics).T\n",
    "        print(\"\\nPerformance metrics:\")\n",
    "        print(metrics_df)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    overall_mae_val = mae(val_scaled, forecasts)\n",
    "    print(f\"The MAE for this fold was {overall_mae_val}\")\n",
    "\n",
    "    trial_dict = {\n",
    "        \"trial_number\": trial.number,\n",
    "        \"overall_mae_val\": overall_mae_val,\n",
    "        \"params\": params,\n",
    "        \"metrics\": metrics_df.to_dict(),\n",
    "    }\n",
    "    json_path = os.path.join(results_output_dir, f\"trial_{trial.number}.json\")\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(trial_dict, f, indent=4)\n",
    "    print(f\"Results of trial {trial.number} saved in {json_path}\")\n",
    "    return overall_mae_val if not np.isnan(overall_mae_val) else float(\"inf\")\n"
   ],
   "id": "a8bc803cf0e0af7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ],
   "id": "965c66610ea29d08",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51d771ffa210c7f5",
   "metadata": {},
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "num_hyperparams = 11\n",
    "n_trials = 7 * num_hyperparams\n",
    "study.optimize(objective, n_trials=n_trials, callbacks=[print_callback])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d067f70903d0a12",
   "metadata": {},
   "source": [
    "print(f\"Best Value (Minimum): {study.best_value}\")\n",
    "print(f\"Best Parameters: {study.best_params}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2116824c79bf39cb",
   "metadata": {},
   "source": [
    "best_dict = {\n",
    "    \"best_value\": study.best_value,\n",
    "    \"best_params\": study.best_params,\n",
    "}\n",
    "json_path = os.path.join(results_output_dir, \"best_trial.json\")\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(best_dict, f, indent=4)\n",
    "print(f\"Best results saved in {json_path}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
