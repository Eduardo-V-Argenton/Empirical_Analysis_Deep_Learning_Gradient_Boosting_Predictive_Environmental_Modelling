{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d09c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import BlockRNNModel\n",
    "from darts.metrics import mse\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
    "import optuna\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "torch.set_float32_matmul_precision('medium')"
   ],
   "id": "681348aab4cd9f9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ebe2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = [\n",
    "    'Temperature','Precipitation_accumulated','Humidity', 'Wind_Speed_kmh',\n",
    "    'Soil_Moisture', 'Soil_Temperature', 'Wind_Dir_Sin', 'Wind_Dir_Cos'\n",
    "]\n",
    "\n",
    "DATA_FILE_PATH = \"../data/ground_station_clean.csv\"\n",
    "df = pd.read_csv(DATA_FILE_PATH)"
   ],
   "id": "1aeae5fb20a9461e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a26b25f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "encoders = {\n",
    "    \"cyclic\": {\n",
    "        \"past\": [\"month\", \"dayofyear\", \"day\", \"hour\", \"minute\"],\n",
    "        \"future\": [\"month\", \"dayofyear\", \"day\", \"hour\", \"minute\"]\n",
    "    },\n",
    "    \"transformer\": Scaler(),\n",
    "    \"datetime_attribute\": {\n",
    "        \"past\": [\"year\"],\n",
    "        \"future\": [\"year\"]\n",
    "    }\n",
    "}\n"
   ],
   "id": "def2c882f0e74f35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b598af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchedPruningCallback(PyTorchLightningPruningCallback, Callback):\n",
    "    pass\n",
    "\n",
    "# Create directory to save iteration results\n",
    "results_output_dir = \"optuna_iteration_metrics\"\n",
    "os.makedirs(results_output_dir, exist_ok=True)"
   ],
   "id": "69a1e0daa0e77178",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 5,
   "id": "8018b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def objective(trial):\n",
    "    input_chunk_length = trial.suggest_int(\"input_chunk_length\", 24, 71)\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [32,64,128,256])\n",
    "    layer_size = trial.suggest_int(\"layer_size\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64,128,256])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-6, 5e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0005, patience=15, verbose=True)\n",
    "    prunner = PatchedPruningCallback(trial, monitor=\"val_loss\")\n",
    "    pl_trainer_kwargs = {\n",
    "        \"accelerator\": \"auto\",\n",
    "        \"callbacks\": [early_stopper, prunner],\n",
    "    }\n",
    "\n",
    "    n_splits = 5\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    overall_mse_list = []\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, val_index in tscv.split(df):\n",
    "        print(f\"\\nFold {fold+1}/{n_splits}\")\n",
    "        train_df_fold = df.iloc[train_index]\n",
    "        val_df_fold = df.iloc[val_index]\n",
    "        train_fold = TimeSeries.from_dataframe(train_df_fold, time_col=\"Timestamp\", value_cols=target_columns, freq='1h')\n",
    "        val_fold = TimeSeries.from_dataframe(val_df_fold, time_col=\"Timestamp\", value_cols=target_columns, freq='1h')\n",
    "\n",
    "        scaler = Scaler()\n",
    "        scaler = scaler.fit(train_fold)\n",
    "        train_scaled = scaler.transform(train_fold)\n",
    "        val_scaled = scaler.transform(val_fold)\n",
    "\n",
    "        opt_kwargs = {\"lr\": lr, \"weight_decay\": weight_decay}\n",
    "\n",
    "        model = BlockRNNModel(\n",
    "            model=\"GRU\",\n",
    "            model_name=f\"model_{fold+1}\",\n",
    "            work_dir=\"/home/eduardo/Documentos/Water-Cycle-Neural-Network/darts_logs\",\n",
    "            input_chunk_length=input_chunk_length,\n",
    "            output_chunk_length=72,\n",
    "            hidden_dim=hidden_size,\n",
    "            n_rnn_layers=layer_size,\n",
    "            n_epochs=30,\n",
    "            batch_size=batch_size,\n",
    "            dropout=dropout,\n",
    "            add_encoders=encoders,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "            loss_fn=torch.nn.MSELoss(),\n",
    "            optimizer_cls=torch.optim.Adam,\n",
    "            lr_scheduler_cls=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            lr_scheduler_kwargs={\"mode\": \"min\", \"factor\": 0.3, \"patience\": 7, \"min_lr\": 1e-7},\n",
    "            save_checkpoints=True,\n",
    "            show_warnings=True,\n",
    "            force_reset=True,\n",
    "            random_state=42,\n",
    "            optimizer_kwargs=opt_kwargs,\n",
    "        )\n",
    "        model.fit(\n",
    "            series=train_scaled,\n",
    "            val_series=val_scaled,\n",
    "            verbose=False,\n",
    "            dataloader_kwargs={\"num_workers\": 11},\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            loaded_model = model.load_from_checkpoint(f\"/home/eduardo/Documentos/Water-Cycle-Neural-Network/darts_logs/model_{fold+1}\", best=True)\n",
    "            print(f\"Model loaded from checkpoint for trial {trial.number}, fold {fold}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Checkpoint not found. Using the in-memory trained model.\")\n",
    "            loaded_model = model\n",
    "\n",
    "        forecasts = loaded_model.historical_forecasts(\n",
    "            val_scaled,\n",
    "            forecast_horizon=72,\n",
    "            stride=1,\n",
    "            retrain=False,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        forecasts_t = scaler.inverse_transform(forecasts)\n",
    "        s = scaler.inverse_transform(val_scaled)\n",
    "        overall_mse_val = mse(s, forecasts_t)\n",
    "        overall_mse_list.append(overall_mse_val)\n",
    "        print(f\"MSE fold {fold}: {overall_mse_val}\")\n",
    "        fold += 1\n",
    "\n",
    "    mean_mse = np.mean(overall_mse_list)\n",
    "    print(f\"Média dos MSE nos folds: {mean_mse}\")\n",
    "\n",
    "    trial_dict = {\n",
    "        \"trial_number\": trial.number,\n",
    "        \"fold_mse\": overall_mse_list,\n",
    "        \"mean_mse\": mean_mse,\n",
    "        \"hyperparameters\": trial.params\n",
    "    }\n",
    "    json_path = os.path.join(results_output_dir, f\"trial_{trial.number}.json\")\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(trial_dict, f, indent=4)\n",
    "    print(f\"Results of trial {trial.number} saved in {json_path}\")\n",
    "    return mean_mse if not np.isnan(mean_mse) else float(\"inf\")"
   ],
   "id": "cbdcf1ba45ca6e34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ed8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ],
   "id": "e7ad5da321e5c18b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "num_hyperparams = 7\n",
    "n_trials = 10 * num_hyperparams\n",
    "study.optimize(objective, n_trials=n_trials, callbacks=[print_callback])"
   ],
   "id": "e8e89ff3d4c6e2c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Best Value (Minimum): {study.best_value}\")\n",
    "print(f\"Best Parameters: {study.best_params}\")"
   ],
   "id": "e4c72edcd48f85a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 9,
   "id": "83b68ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores resultados salvos em optuna_iteration_metrics/best_trial.json\n"
     ]
    }
   ],
   "source": [
    "best_dict = {\n",
    "    \"best_value\": study.best_value,\n",
    "    \"best_params\": study.best_params,\n",
    "}\n",
    "json_path = os.path.join(results_output_dir, \"best_trial.json\")\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(best_dict, f, indent=4)\n",
    "print(f\"Best results saved in {json_path}\")"
   ],
   "id": "2711eb20a35fec40",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (TORCH)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
